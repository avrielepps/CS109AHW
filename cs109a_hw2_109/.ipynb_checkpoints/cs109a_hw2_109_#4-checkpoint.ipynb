{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "\n",
    "## Homework 2: Linear and k-NN Regression\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader\n",
    "\n",
    "<hr style=\"height:2pt\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- If you submit individually and you have worked with someone, please include the name of your [one] partner below. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names of people you have worked with goes here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avriel Epps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "import seaborn as sns\n",
    "from pandas.core import datetools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"theme\"> Predicting Taxi Pickups in NYC </div>\n",
    "\n",
    "In this homework, we will explore k-nearest neighbor and linear regression methods for predicting a quantitative variable. Specifically, we will build regression models that can predict the number of taxi pickups in New York city at any given time of the day. These prediction models will be useful, for example, in monitoring traffic in the city.\n",
    "\n",
    "The data set for this problem is given in the file `dataset_1.csv`.  You will need to separate it into training and test sets. The first column contains the time of a day in minutes, and the second column contains the number of pickups observed at that time. The data set covers taxi pickups recorded in NYC during Jan 2015.\n",
    "\n",
    "We will fit regression models that use the time of the day (in minutes) as a predictor and predict the average number of taxi pickups at that time. The models will be fitted to the training set and  evaluated on the test set. The performance of the models will be evaluated using the $R^2$ metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"> <b> Question 1  [25 pts]</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1**. Use pandas to load the dataset from the csv file `dataset_1.csv` into a pandas data frame.  Use the `train_test_split` method from `sklearn` with a `random_state` of 42 and a `test_size` of 0.2 to split the dataset into training and test sets.  Store your train set dataframe in the variable `train_data`.  Store your test set dataframe in the variable `test_data`.\n",
    "\n",
    "\n",
    "**1.2**. Generate a scatter plot of the training data points with clear labels on the x and y axes. The time of the day on the x-axis and the number of taxi pickups on the y-axis.  Make sure to title your plot.\n",
    "\n",
    "**1.3**. Does the pattern of taxi pickups make intuitive sense to you? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Use pandas to load the dataset from the csv file ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the file\n",
    "data = pd.read_csv('data/dataset_1.csv', sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TimeMin', 'PickupCount'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeMin</th>\n",
       "      <th>PickupCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>860.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>486.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>385.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimeMin  PickupCount\n",
       "0    860.0         33.0\n",
       "1     17.0         75.0\n",
       "2    486.0         13.0\n",
       "3    300.0          5.0\n",
       "4    385.0         10.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check that it imported correctly -- delete before turning in\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data['Time (TimeMin)'].astype(str)\n",
    "#data['Pick Up Count'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the data\n",
    "train_data, test_data = train_test_split(data, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = train_data['TimeMin'], train_data['PickupCount']\n",
    "x_test, y_test = test_data['TimeMin'], test_data['PickupCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test size is indeed 20% of total\n",
    "data20 = .2*len(data)\n",
    "our20 = len(test_data)\n",
    "print(\"20% of data:\",data20,\"Our split data:\", our20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Generate a scatter plot of the training data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sns.relplot(x=\"Time of Day\", y=\"Number of Pickups\", data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nice_scatterplot(x, y, title):\n",
    "    # font size\n",
    "    f_size = 18\n",
    "    \n",
    "    # make the figure\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,5)) # Create figure object\n",
    "\n",
    "    # set axes limits to make the scale nice\n",
    "    ax.set_xlim(np.min(x)-1, np.max(x) + 1)\n",
    "    ax.set_ylim(np.min(y)-1, np.max(y) + 1)\n",
    "\n",
    "    # adjust size of tickmarks in axes\n",
    "    ax.tick_params(labelsize = f_size)\n",
    "    \n",
    "    # remove tick labels\n",
    "    ax.tick_params(labelbottom=False,  bottom=False)\n",
    "    \n",
    "    # adjust size of axis label\n",
    "    ax.set_xlabel(r'$x$', fontsize = f_size)\n",
    "    ax.set_ylabel(r'$y$', fontsize = f_size)\n",
    "    \n",
    "    # set figure title label\n",
    "    ax.set_title(title, fontsize = f_size)\n",
    "\n",
    "    # you may set up grid with this \n",
    "    ax.grid(True, lw=1.75, ls='--', alpha=0.15)\n",
    "\n",
    "    # make actual plot (Notice the label argument!)\n",
    "    #ax.scatter(x, y, label=r'$my points$')\n",
    "    #ax.scatter(x, y, label='$my points$')\n",
    "    ax.scatter(x, y, label=r'$my\\,points$')\n",
    "    ax.legend(loc='best', fontsize = f_size);\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_scatterplot(data[\"TimeMin\"],data[\"PickupCount\"],\"Time of Day vs. Taxi Pick Ups\")\n",
    "plt.xlabel(\"Time of Day\")\n",
    "plt.ylabel(\"Number of Taxi Pick Ups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "plt.scatter(x_train,y_train)\n",
    "plt.title('Predicting Taxi Pick-Ups in New York')\n",
    "plt.xlabel(\"Time of Day in Minutes\")\n",
    "plt.ylabel(\"Number of Taxi Pick Ups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Discuss your results. Does the pattern of taxi pickups make intuitive sense to you?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"> <b>Question 2 [25 pts]</b> </div>\n",
    "\n",
    "In lecture we've seen k-Nearest Neighbors (k-NN) Regression, a non-parametric regression technique.  In the following problems please use built in functionality from `sklearn` to run k-NN Regression. \n",
    "\n",
    "\n",
    "**2.1**. Choose `TimeMin` as your feature variable and `PickupCount` as your response variable.  Create a dictionary of `KNeighborsRegressor` objects and call it `KNNModels`.  Let the key for your `KNNmodels` dictionary be the value of $k$ and the value be the corresponding `KNeighborsRegressor` object. For $k \\in \\{1, 10, 75, 250, 500, 750, 1000\\}$, fit k-NN regressor models on the training set (`train_data`). \n",
    "\n",
    "**2.2**.  For each $k$ on the training set, overlay a scatter plot of the actual values of `PickupCount` vs. `TimeMin` with a scatter plot of **predictions** for `PickupCount` vs  `TimeMin`.  Do the same for the test set.  You should have one figure with 2 x 7 total subplots; for each $k$ the figure should have two subplots, one subplot for the training set and one for the test set. \n",
    "\n",
    "**Hints**:\n",
    "1. Each subplot should use different color and/or markers to distinguish k-NN regression prediction values from the actual data values.\n",
    "2. Each subplot must have appropriate axis labels, title, and legend.\n",
    "3. The overall figure should have a title.  \n",
    "\n",
    "\n",
    "**2.3**. Report the $R^2$ score for the fitted models on both the training and test sets for each $k$ (reporting the values in tabular form is encouraged).\n",
    "\n",
    "**2.4**. Plot, in a single figure, the $R^2$ values from the model on the training and test set as a function of $k$.  \n",
    "\n",
    "**Hints**:\n",
    "1. Again, the figure must have axis labels and a legend.\n",
    "2. Differentiate $R^2$ visualization on the training and test set by color and/or marker.\n",
    "3. Make sure the $k$ values are sorted before making your plot.\n",
    "\n",
    "**2.5**. Discuss the results:\n",
    "\n",
    "1. If $n$ is the number of observations in the training set, what can you say about a k-NN regression model that uses $k = n$?  \n",
    "2. What does an $R^2$ score of $0$ mean?  \n",
    "3. What would a negative $R^2$ score mean?  Are any of the calculated $R^2$ you observe negative?\n",
    "4. Do the training and test $R^2$ plots exhibit different trends?  Describe.  \n",
    "5. How does the value of $k$ affect the fitted model and in particular the training and test $R^2$ values?\n",
    "6. What is the best value of $k$ and what are the corresponding training/test set $R^2$ values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Choose `TimeMin` as your feature variable and `PickupCount` as your response variable.  Create a dictionary ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set kNN parameter:\n",
    "k = 10\n",
    "\n",
    "# Now we can fit the model, predict our variable of interest, and then evaluate our fit:\n",
    "# First, we create the classifier object:\n",
    "neighbors = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "# Then, we fit the model using x_train as training data and y_train as target values:\n",
    "neighbors.fit(train_data[['TimeMin']], train_data['PickupCount'])\n",
    "\n",
    "neighbors\n",
    "\n",
    "# Retreieve our predictions:\n",
    "prediction_knn = neighbors.predict(test_data[['TimeMin']])\n",
    "\n",
    "#put this in a function\n",
    "def get_knn(k):\n",
    "    neighbors = KNeighborsRegressor(n_neighbors=k)\n",
    "    neighbors.fit(train_data[['TimeMin']], train_data['PickupCount'])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNModels = {}\n",
    "KNNModels['1']=get_knn(k=1)\n",
    "KNNModels['10']=get_knn(k=10)\n",
    "KNNModels['75']=get_knn(k=75)\n",
    "KNNModels['250']=get_knn(k=250)\n",
    "KNNModels['500']=get_knn(k=500)\n",
    "KNNModels['750']=get_knn(k=750)\n",
    "KNNModels['1000']=get_knn(k=1000)\n",
    "\n",
    "KNNModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 For each $k$ on the training set, overlay a scatter plot ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in (1, 10, 75, 250, 500, 750, 1000):\n",
    "    neighbors = get_knn(k)\n",
    "\n",
    "    # Then, we fit the model using x_train as training data and y_train as target values:\n",
    "    neighbors.fit(train_data[['TimeMin']], train_data['PickupCount'])\n",
    "\n",
    "    # Retreieve our predictions:\n",
    "    prediction_knn = neighbors.predict(test_data[['TimeMin']])\n",
    "\n",
    "    #plot\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,6))\n",
    "    axes[0].plot(train_data['TimeMin'], train_data['PickupCount'], 'o', label = 'Data' )\n",
    "    axes[0].plot(train_data['TimeMin'], neighbors.predict(train_data[['TimeMin']]), '*', label = 'Prediction')\n",
    "    axes[0].set_xlabel('Time of Day in Minutes')\n",
    "    axes[0].set_ylabel('# of Pickups')\n",
    "    axes[0].set_title(\"Training Set\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(test_data['TimeMin'], test_data['PickupCount'],'o', label = 'Data' )\n",
    "    axes[1].plot(test_data['TimeMin'], prediction_knn, '*', label = 'Prediction')\n",
    "    axes[1].set_xlabel('Time of Day in Minutes')\n",
    "    axes[1].set_ylabel('# of Pickups')\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    fig.suptitle(f\"Taxi Pickups in New York When k ={k}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Report the $R^2$ score for the fitted models ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_r_2(k):\n",
    "    array_train, array_test = [],[]\n",
    "    for k in (1, 10, 75, 250, 500, 750, 1000):\n",
    "        neighbors = get_knn(k)\n",
    "        r2_train = neighbors.score(train_data[['TimeMin']], train_data['PickupCount'])\n",
    "        r2_test = neighbors.score(test_data[['TimeMin']], test_data['PickupCount'])\n",
    "        print(\"Length of Test Data:\", len(test_data['PickupCount']))\n",
    "        print(\"k:\", k)\n",
    "        print(\"R^2 Score of kNN on test set:\", r2_test)\n",
    "        print(\"R^2 Score of kNN on training set:\", r2_train)\n",
    "        print(\"\\n\")\n",
    "        array_train.append(r2_train)\n",
    "        array_test.append(r2_test)\n",
    "    return array_train, array_test\n",
    "    \n",
    "    \n",
    "array_test, array_train = get_r_2(k)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Plot, in a single figure, the $R^2$ values from the model on the training and test set as a function of $k$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ks = [1, 10, 75, 250, 500, 750, 1000]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,9))\n",
    "ax.plot(ks, array_train,'-o', label = 'Train R^2 Values' )\n",
    "ax.plot(ks, array_test,'-*', label = 'Test R^2 Values' )\n",
    "ax.set_xlabel(r'$k$')\n",
    "ax.set_ylim([-0.5, 1])\n",
    "ax.set_ylabel(r'$R^{2}$')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Discuss the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If $n$ is the number of observations in the training set, what can you say about a k-NN regression model that uses $k = n$?  \n",
    "2. What does an $R^2$ score of $0$ mean?  \n",
    "3. What would a negative $R^2$ score mean?  Are any of the calculated $R^2$ you observe negative?\n",
    "4. Do the training and test $R^2$ plots exhibit different trends?  Describe.  \n",
    "5. How does the value of $k$ affect the fitted model and in particular the training and test $R^2$ values?\n",
    "6. What is the best value of $k$ and what are the corresponding training/test set $R^2$ values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"> <b> Question 3 [25 pts] </b></div>\n",
    "\n",
    "We next consider simple linear regression, which we know from lecture is a parametric approach for regression that assumes that the response variable has a linear relationship with the predictor.  Use the `statsmodels` module for Linear Regression. This module has built-in functions to summarize the results of regression and to compute confidence intervals for estimated regression parameters.  \n",
    "\n",
    "**3.1**. Again choose `TimeMin` as your predictor and `PickupCount` as your response variable.  Create a `OLS` class instance and use it to fit a Linear Regression model on the training set (`train_data`).  Store your fitted model in the variable `OLSModel`.\n",
    "\n",
    "**3.2**. Re-create your plot from 2.2 using the predictions from `OLSModel` on the training and test set. You should have one figure with two subplots, one subplot for the training set and one for the test set.\n",
    "\n",
    "**Hints**:\n",
    "1. Each subplot should use different color and/or markers to distinguish Linear Regression prediction values from that of the actual data values.\n",
    "2. Each subplot must have appropriate axis labels, title, and legend.\n",
    "3. The overall figure should have a title.  \n",
    "\n",
    "\n",
    "**3.3**. Report the $R^2$ score for the fitted model on both the training and test sets.\n",
    "\n",
    "**3.4**. Report the slope and intercept values for the fitted linear model.  \n",
    "\n",
    "**3.5**. Report the $95\\%$ confidence interval for the slope and intercept.\n",
    "\n",
    "**3.6**. Create a scatter plot of the residuals ($e = y - \\hat{y}$) of the linear regression model on the training set as a function of the predictor variable (i.e. `TimeMin`). Place on your plot a horizontal line denoting the constant zero residual.  \n",
    "\n",
    "**3.7**. Discuss the results:\n",
    "\n",
    "1. How does the test $R^2$ score compare with the best test $R^2$ value obtained with k-NN regression?\n",
    "2. What does the sign of the slope of the fitted linear model convey about the data?  \n",
    "3. Based on the $95\\%$ confidence interval, do you consider the estimates of the model parameters to be reliable?  \n",
    "4. Do you expect $99\\%$ confidence intervals for the slope and intercept to be tighter or wider than the $95\\%$ confidence intervals? Briefly explain your answer.  \n",
    "5. Based on the residuals plot that you made, discuss whether or not the assumption of linearity is valid for this data.\n",
    "6. Based on the data structure, what restriction on the model would you put at the endpoints (at $x\\approx0$ and $x\\approx1440$)?   What does this say about the linearity assumption?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Again choose `TimeMin` as your predictor and `PickupCount` as your response variable.  Create a `OLS` class instance ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add constant\n",
    "x_ca = sm.add_constant(data['TimeMin'])\n",
    "x_train_ca = sm.add_constant(x_train)\n",
    "x_test_ca = sm.add_constant(x_test)\n",
    "\n",
    "#We must first create the linear regression object from stats model\n",
    "OLSmodel = sm.OLS(y_train, x_train_ca)\n",
    "results = OLSmodel.fit()\n",
    "display(results.summary())\n",
    "\n",
    "#predict y\n",
    "predicted_y = results.predict(x_ca)\n",
    "predicted_y_train = results.predict(x_train_ca)\n",
    "predicted_y_test = results.predict(x_test_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Re-create your plot from 2.2 using the predictions from `OLSModel` on the training and test set ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,6))\n",
    "axes[0].plot(train_data['TimeMin'], train_data['PickupCount'],'o', label = 'Data' )\n",
    "axes[0].plot(train_data['TimeMin'], predicted_y_train, '-*', label = 'Prediction')\n",
    "axes[0].set_xlabel('Time of Day in Minutes')\n",
    "axes[0].set_ylabel('# of Pickups')\n",
    "axes[0].set_title(\"Train Set\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(test_data['TimeMin'], test_data['PickupCount'], 'o', label = 'Test Data' )\n",
    "axes[1].plot(test_data['TimeMin'], predicted_y_test, '-*', label = 'Prediction')\n",
    "axes[1].set_xlabel('Time of Day in Minutes')\n",
    "axes[1].set_ylabel('# of Pickups')\n",
    "axes[1].set_title(\"Test Set\")\n",
    "axes[1].legend()\n",
    "\n",
    "fig.suptitle(\"OLS Predictions for Taxi Pickups in New York\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Report the $R^2$ score for the fitted model on both the training and test sets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"R^2 Score for Linear Regression (Training):\", (results.rsquared))\n",
    "print(\"R^2 Score for Linear Regression (Testing) :\", (r2_score(test_data['PickupCount'], predicted_y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4 Report the slope and intercept values for the fitted linear model.  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = OLSmodel.fit()\n",
    "display(results.params)\n",
    "\n",
    "#or\n",
    "\n",
    "beta0_sm = results.params[0]\n",
    "beta1_sm = results.params[1]\n",
    "\n",
    "print(\"The intercept value is {0:8.6f}, and the slope value is {1:8.6f}\".format(beta0_sm, beta1_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5 Report the $95\\%$ confidence interval for the slope and intercept.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.05\n",
    "intervals = results.conf_int(alpha=thresh)\n",
    "intervals = intervals.rename(index=str, columns={0:str(thresh/2*100)+\"%\",1:str((1-thresh/2)*100)+\"%\"})\n",
    "display(intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.6 Create a scatter plot of the residuals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "residual = data['PickupCount']-predicted_y\n",
    "display(residual.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.scatter(data['TimeMin'], residual)\n",
    "plt.xlabel(\"X1 - a predictor\")\n",
    "plt.ylabel(\"residual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.7 Discuss the results:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How does the test $R^2$ score compare with the best test $R^2$ value obtained with k-NN regression?\n",
    "2. What does the sign of the slope of the fitted linear model convey about the data?  \n",
    "3. Based on the $95\\%$ confidence interval, do you consider the estimates of the model parameters to be reliable?  \n",
    "4. Do you expect $99\\%$ confidence intervals for the slope and intercept to be tighter or wider than the $95\\%$ confidence intervals? Briefly explain your answer.  \n",
    "5. Based on the residuals plot that you made, discuss whether or not the assumption of linearity is valid for this data.\n",
    "6. Based on the data structure, what restriction on the model would you put at the endpoints (at $x\\approx0$ and $x\\approx1440$)?   What does this say about the linearity assumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"theme\"> Outliers </div>\n",
    "\n",
    "You may recall from lectures that OLS Linear Regression can be susceptible to outliers in the data.  We're going to look at a dataset that includes some outliers and get a sense for how that affects modeling data with Linear Regression.  **Note, this is an open-ended question, there is not one correct solution (or one correct definition of an outlier).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b> Question 4 [25 pts] </b></div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**4.1**. We've provided you with two files `outliers_train.txt` and `outliers_test.txt` corresponding to training set and test set data.  What does a visual inspection of training set tell you about the existence of outliers in the data?\n",
    "\n",
    "**4.2**. Choose `X` as your feature variable and `Y` as your response variable.  Use `statsmodel` to create a Linear Regression model on the training set data.  Store your model in the variable `OutlierOLSModel`.\n",
    "\n",
    "**4.3**. You're given the knowledge ahead of time that there are 3 outliers in the training set data.  The test set data doesn't have any outliers.  You want to remove the 3 outliers in order to get the optimal intercept and slope.  In the case that you're sure of the existence and number (3) of outliers ahead of time, one potential brute force method to outlier detection might be to find the best Linear Regression model on all possible subsets of the training set data with 3 points removed.  Using this method, how many times will you have to calculate the Linear Regression coefficients on the training data?\n",
    "\n",
    "**4.4**  In CS109 we're strong believers that creating heuristic models is a great way to build intuition. In that spirit, construct an approximate algorithm to find the 3 outlier candidates in the training data by taking advantage of the Linear Regression residuals. Place your algorithm in the function `find_outliers_simple`.  It should take the parameters `dataset_x` and `dataset_y` representing your features and response variable values (make sure your response variable is stored as a numpy column vector).  The return value should be a list `outlier_indices` representing the indices of the 3 outliers in the original datasets you passed in.  Remove the outliers that your algorithm identified, use `statsmodels` to create a Linear Regression model on the remaining training set data, and store your model in the variable `OutlierFreeSimpleModel`.\n",
    "\n",
    "\n",
    "**4.5** Create a figure with two subplots: the first is a scatterplot where the color of the points denotes the outliers from the non-outliers in the training set, and include two regression lines on this scatterplot: one fitted with the outliers included and one fitted with the outlier removed (all on the training set).  The second plot should include a scatterplot of points from the test set with the same two regression lines fitted on the training set: with and without outliers.  Visually which model fits the test set data more closely?\n",
    "\n",
    "\n",
    "\n",
    "**4.6**. Calculate the $R^2$ score for the `OutlierOLSModel` and the `OutlierFreeSimpleModel` on the test set data.  Which model produces a better $R^2$ score?\n",
    "\n",
    "**4.7**. One potential problem with the brute force outlier detection approach in 4.3 and the heuristic algorithm you constructed 4.4 is that they assume prior knowledge of the number of outliers.  In general you can't expect to know ahead of time the number of outliers in your dataset.  Alter the algorithm you constructed in 4.4 to create a more general heuristic (i.e. one which doesn't presuppose the number of outliers) for finding outliers in your dataset.  Store your algorithm in the function `find_outliers_general`.  It should take the parameters `dataset_x` and `dataset_y` representing your features and response variable values (make sure your response variable is stored as a numpy column vector).  It can take additional parameters as long as they have default values set.  The return value should be the list `outlier_indices` representing the indices of the outliers in the original datasets you passed in (in the order of 'severity').  Remove the outliers that your algorithm identified, use `statsmodels` to create a Linear Regression model on the remaining training set data, and store your model in the variable `OutlierFreeGeneralModel`.\n",
    "\n",
    "**Hints**:\n",
    "   1. How many outliers should you try to identify in each step?\n",
    "   2. If you plotted an $R^2$ score for each step the algorithm, what might that plot tell you about stopping conditions?\n",
    "    \n",
    "**4.8**. Run your algorithm in 4.7 on the training set data.  \n",
    "1. What outliers does it identify?\n",
    "2. How do those outliers compare to the outliers you found in 4.4?\n",
    "3. How does the general outlier-free Linear Regression model you created in 4.7 perform compared to the simple one in 4.4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "**4.1  We've provided you with two files `outliers_train.txt` and `outliers_test.txt` corresponding to training set and test set data.  What does a visual inspection of training set tell you about the existence of outliers in the data? ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "# your code here\n",
    "train_data = pd.read_csv('data/outliers_train.csv', sep=\",\")\n",
    "test_data = pd.read_csv('data/outliers_train.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def nice_scatterplot(x, y, title):\n",
    "    # font size\n",
    "    f_size = 18\n",
    "    \n",
    "    # make the figure\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,5)) # Create figure object\n",
    "\n",
    "    # set axes limits to make the scale nice\n",
    "    ax.set_xlim(np.min(x)-1, np.max(x) + 1)\n",
    "    ax.set_ylim(np.min(y)-1, np.max(y) + 1)\n",
    "\n",
    "    # adjust size of tickmarks in axes\n",
    "    ax.tick_params(labelsize = f_size)\n",
    "    \n",
    "    # remove tick labels\n",
    "    ax.tick_params(labelbottom=False,  bottom=False)\n",
    "    \n",
    "    # adjust size of axis label\n",
    "    ax.set_xlabel(r'$x$', fontsize = f_size)\n",
    "    ax.set_ylabel(r'$y$', fontsize = f_size)\n",
    "    \n",
    "    # set figure title label\n",
    "    ax.set_title(title, fontsize = f_size)\n",
    "\n",
    "    # you may set up grid with this \n",
    "    ax.grid(True, lw=1.75, ls='--', alpha=0.15)\n",
    "\n",
    "    # make actual plot (Notice the label argument!)\n",
    "    #ax.scatter(x, y, label=r'$my points$')\n",
    "    #ax.scatter(x, y, label='$my points$')\n",
    "    ax.scatter(x, y, label=r'$my\\,points$')\n",
    "    ax.legend(loc='best', fontsize = f_size);\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "nice_scatterplot(train_data[\"X\"],train_data[\"Y\"],\"Outliers: X v. Y\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "plt.scatter(train_data[\"X\"],train_data[\"Y\"])\n",
    "plt.title('Predicting Taxi Pick-Ups in New York')\n",
    "plt.xlabel(\"Time of Day in Minutes\")\n",
    "plt.ylabel(\"Number of Taxi Pick Ups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Choose `X` as your feature variable and `Y` as your response variable.  Use `statsmodel` to create ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 One potential brute force method to outlier detection might be to find the best Linear Regression model on all possible subsets of the training set data with 3 points removed.  Using this method, how many times will you have to calculate the Linear Regression coefficients on the training data?**\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4 CS109 hack ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_outliers_simple(dataset_x, dataset_y):\n",
    "    # your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get outliers\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_outliers_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate outlier model\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.5 Create a figure with two subplots: the first is a scatterplot ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.6  Calculate the $R^2$ score for the `OutlierOLSModel` and the `OutlierFreeSimpleModel` on the test set data.  Which model produces a better $R^2$ score?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.7 One potential problem with the brute force outlier detection approach in 4.3 and the heuristic algorithm you constructed 4.4 is that they assume prior knowledge of the number of outliers. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.8 Run your algorithm in 4.7 on the training set data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
