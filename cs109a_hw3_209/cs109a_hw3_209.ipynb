{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "\n",
    "## Homework 3  AC 209 : From MLE to AIC\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader\n",
    "\n",
    "<hr style=\"height:2pt\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import t\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class='exercise'> <b>  Question 7: Student's t MLE </b> </div>\n",
    "\n",
    "**7.1** Fit a simple linear regression model using Maximum Likelihood Estimation on the data provided in `data/beerdata.csv`.  Consider two statistical models the for noise: a) Normal and b) Student's $\\textit{t}$-distribution with $\\nu=5$ and scale factor $\\sigma=\\sqrt{3/5}$.  \n",
    "\n",
    "**7.2** Compare the two models performances (visualize the prediction lines and estimate the KL divergence between the data and each model) and comment why it is perhaps appropriate to use the Student's t-distribution instead of the Normal.\n",
    "\n",
    "**Hints:**\n",
    "1. Use the probability density function for the Student's t distribution  with location $t$,  $\\nu$ degrees of freedom and scale factor $\\sigma$.\n",
    "2. If the MLE regression coefficients cannot be derived analytically consider numerical methods.\n",
    "3. For _convenience_, you can use sklearn or statsmodel for the Normal case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "**7.1 Fit a simple linear regression model using Maximum Likelihood Estimation on the data provided in `data/beerdata.csv`.  Consider two statistical models the for noise: a) Normal and b) Student's $\\textit{t}$-distribution with $\\nu=5$ and scale factor $\\sigma=\\sqrt{3/5}$.   **\n",
    "\n",
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read and show the data\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot the data\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate the ordinary least squares model (OLS)\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot the data along with OLS fit line\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LET'S MAKE THE REGRESSION MODEL WITH t-Students distribution\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2 Compare the two models performances (visualize the prediction lines and estimate the KL divergence between the data and each model) and comment why it is perhaps appropriate to use the Student's t-distribution instead of the Normal. **\n",
    "\n",
    "\n",
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class='exercise'> <b>  Question 8: Akaike Information Criterion (AIC) </b> </div>\n",
    "\n",
    "Perform a simple numerical experiment to understand and demonstrate the AIC by using the given `generate_data` function to generate your data.\n",
    " \n",
    "\n",
    "**8.1**\n",
    "Generate data for different number of parameters $k$, in the range 1 to 10. For each of the six models generate 1000 training and 1000 testing datasets with each one containing $n=50$ observations.\n",
    "\n",
    "**8.2** \n",
    "Use the training set to estimate the OLS coefficients and  calculate the predicted values, $\\hat y_{tr}$, on the training set and the log-likelihood. \n",
    " Use the OLS coefficients to calculate the predicted values  for the testing set, $\\hat y_{te}$, and the associated log-likelihood. \n",
    "\n",
    "**8.3** \n",
    "For each $k$ compute the average and standard deviation of the log-likelihoods across the 1000 simulations.  Plot the average  log-likelihoods (with error bars) and the average AIC as function of $k$, the number of parameters. What is the best $k$ based on AIC?\n",
    "\n",
    "**8.4**\n",
    "Verify the results in 8.3 by plotting the average log-likelihoods for each of the training and testing datasets as a function of $k$. What is the best $k$ based on this plot?\n",
    "\n",
    "\n",
    "**Comment:**\n",
    "1. The function \"generate_data\" uses an interesting trick to generate data directly using the regression coefficients as proxies for the correlations with the response variable. It generates data from a Normal distribution, hence $y_i \\sim \\mathcal{N}(\\mu_i= 0.15 x_{1,i} - 0.4 x_{2,i},\\sigma^2=1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N,k,beta=[0.15 , -0.4]):\n",
    "    \n",
    "    ## N: The number of observations\n",
    "    ## k: The number of parameters\n",
    "    ## beta is the weights vector for the covariates x1, x2\n",
    "    ##\n",
    "    ## Make d_min be greater or equal to k\n",
    "    n_dim = 1+len(beta)\n",
    "    if (n_dim <= k):\n",
    "        n_dim = k\n",
    "\n",
    "    Rho = np.eye(n_dim)\n",
    "    \n",
    "    # Add beta in the first row or Rho\n",
    "    for i,r in enumerate(beta):\n",
    "        Rho[0,i+1] = r\n",
    "    \n",
    "    index_lower = np.tril_indices(n_dim, -1)\n",
    "    \n",
    "    Rho[index_lower] = Rho.T[index_lower]\n",
    "    mean = n_dim * [0.]        \n",
    "    Xtrain = np.random.multivariate_normal(mean, Rho, size=N)\n",
    "    Xtest = np.random.multivariate_normal(mean, Rho, size=N)\n",
    "    ytrain = Xtrain[:,0].copy()\n",
    "    Xtrain[:,0]=1.\n",
    "    ytest = Xtest[:,0].copy()\n",
    "    Xtest[:,0]=1.\n",
    "    return Xtrain[:,:k], ytrain, Xtest[:,:k], ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "**8.1 Generate data for different number of parameters $k$, in the range 1 to 10. For each of the six models generate 1000 training and 1000 testing datasets with each one containing $n=50$ observations. **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Be familiar with the generated data by printing them:\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2 Use the training set to estimate the OLS coefficients and  calculate the predicted values, $\\hat y_{tr}$, on the training set and the log-likelihood. \n",
    " Use the OLS coefficients to calculate the predicted values  for the testing set, $\\hat y_{te}$, and the associated log-likelihood. **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate the datasets:\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.3\n",
    "For each $k$ compute the average and standard deviation of the log-likelihoods across the 2000 simulations.  Plot the average  log-likelihoods (with error bars) and the average AIC as function of $k$, the number of parameters. What is the best $k$ based on AIC?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot the log-likelihood for the traing and testing:\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**8.4\n",
    "Verify the results in 8.3 by plotting the average log-likelihoods for each of the training and testing datasets as a function of $k$. What is the best $k$ based on this plot?\n",
    "**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot the log-likelihood for the traing and testing:\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
